from fastapi import FastAPI, HTTPException, Body
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import spacy
import networkx as nx
import math
import re
import nltk
from nltk.corpus import stopwords
import unicodedata
import json
from networkx.readwrite import json_graph
import os

# ConfiguraÃ§Ãµes iniciais do NLTK
nltk.download('stopwords')
nltk.download('rslp')

# Inicializa a aplicaÃ§Ã£o FastAPI
app = FastAPI()

# Configura CORS para permitir acesso de qualquer origem
app.add_middleware(
Â  Â  CORSMiddleware,
Â  Â  allow_origins=["*"],
Â  Â  allow_credentials=True,
Â  Â  allow_methods=["*"],
Â  Â  allow_headers=["*"],
)

# VariÃ¡veis globais para os recursos carregados
G = None
nlp = None


# Modelo Pydantic para entrada (nÃ£o serÃ¡ usado diretamente mas mantido para documentaÃ§Ã£o)
class NoticiaRequest(BaseModel):
Â  Â  conteudo: str


base_dir = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(base_dir, "grafo_json.json")

@app.on_event("startup")
def carregar_recursos():
Â  Â  global G, nlp

Â  Â  try:
Â  Â  Â  Â  with open(json_path, "r", encoding='utf-8') as f:
Â  Â  Â  Â  Â  Â  loaded_data = json.load(f)
Â  Â  Â  Â  G = json_graph.node_link_graph(loaded_data)
Â  Â  Â  Â  print(f"âœ… Grafo carregado: {len(G.nodes)} nÃ³s, {len(G.edges)} arestas")
Â  Â  except FileNotFoundError:
Â  Â  Â  Â  print(f"âŒ Arquivo nÃ£o encontrado no caminho: {json_path}")
Â  Â  Â  Â  raise RuntimeError("Falha ao carregar grafo de conhecimento: Arquivo nÃ£o encontrado")
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Erro ao carregar grafo: {str(e)}")
Â  Â  Â  Â  raise RuntimeError("Falha ao carregar grafo de conhecimento") from e

Â  Â  try:
Â  Â  Â  Â  nlp = spacy.load("pt_core_news_md")
Â  Â  Â  Â  print("âœ… Modelo spaCy carregado")
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Erro ao carregar modelo spaCy: {str(e)}")
Â  Â  Â  Â  raise RuntimeError("Falha ao carregar modelo de linguagem") from e


# FunÃ§Ã£o de prÃ©-processamento
def pre_processamento(texto):
Â  Â  texto = texto.lower()
Â  Â  texto = unicodedata.normalize('NFKD', texto).encode('ASCII', 'ignore').decode('ASCII')
Â  Â  texto = re.sub(r'[^a-z\s]', ' ', texto)
Â  Â  texto = re.sub(r'\s+', ' ', texto).strip()
Â  Â  tokens = texto.split()
Â  Â  stop_words = set(stopwords.words('portuguese'))
Â  Â  tokens = [palavra for palavra in tokens if palavra not in stop_words]
Â  Â  return ' '.join(tokens)


# FunÃ§Ã£o de extraÃ§Ã£o de triplas (usa o modelo spaCy carregado globalmente)
def extract_triples(text):
Â  Â  doc = nlp(text)
Â  Â  triples = []
Â  Â  for sent in doc.sents:
Â  Â  Â  Â  subj, pred, obj = None, None, None
Â  Â  Â  Â  for token in sent:
Â  Â  Â  Â  Â  Â  if "subj" in token.dep_:
Â  Â  Â  Â  Â  Â  Â  Â  subj = token.text
Â  Â  Â  Â  Â  Â  if token.pos_ == "VERB":
Â  Â  Â  Â  Â  Â  Â  Â  pred = token.lemma_
Â  Â  Â  Â  Â  Â  if "obj" in token.dep_ and token.dep_ in ("dobj", "obj"):
Â  Â  Â  Â  Â  Â  Â  Â  obj = token.text
Â  Â  Â  Â  if subj and pred and obj:
Â  Â  Â  Â  Â  Â  triples.append((subj, pred, obj))
Â  Â  return triples


# FunÃ§Ã£o de cÃ¡lculo de valor de verdade
def calcular_valor_verdade(grafo, sujeito, objeto):
Â  Â  print(f"DEBUG: Verificando sujeito: {sujeito}, objeto: {objeto}")
Â  Â  if sujeito not in grafo or objeto not in grafo:
Â  Â  Â  Â  print(f"DEBUG: Sujeito ou objeto nÃ£o encontrado no grafo.")
Â  Â  Â  Â  return 0.0
Â  Â  try:
Â  Â  Â  Â  caminhos = nx.all_shortest_paths(grafo, sujeito, objeto)
Â  Â  Â  Â  menor_custo = float('inf')
Â  Â  Â  Â  for caminho in caminhos:
Â  Â  Â  Â  Â  Â  custo = sum(math.log(grafo.degree(nÃ³)) for nÃ³ in caminho[1:-1])
Â  Â  Â  Â  Â  Â  if custo < menor_custo:
Â  Â  Â  Â  Â  Â  Â  Â  menor_custo = custo
Â  Â  Â  Â  return 1 / (1 + menor_custo) if menor_custo != float('inf') else 0.0
Â  Â  except nx.NetworkXNoPath:
Â  Â  Â  Â  return 0.0


def verificar_noticia_completa(sentenca):
Â  Â  triplas = extract_triples(pre_processamento(sentenca))
Â  Â  print(f"DEBUG: Triplas extraÃ­das: {triplas}")
Â  Â  if not triplas:
Â  Â  Â  Â  return 0.0, "Nenhuma tripla vÃ¡lida encontrada."

Â  Â  valores_tau = []
Â  Â  for s, p, o in triplas:
Â  Â  Â  Â  tau = calcular_valor_verdade(G, s, o)
Â  Â  Â  Â  print(f"DEBUG: Calculando tau para ({s}, {o}) = {tau}")
Â  Â  Â  Â  valores_tau.append(tau)

Â  Â  tau_final = sum(valores_tau) / len(valores_tau) if valores_tau else 0.0
Â  Â  print(f"DEBUG: Tau final: {tau_final}")
Â  Â  limiar = 0.80
Â  Â  classificacao = "verdadeira" if tau_final > limiar else "falsa"
Â  Â  return tau_final, classificacao


# Endpoint principal da API
@app.post("/verificar-noticia")
async def verificar_noticia(noticia: str = Body(..., media_type="text/plain")):
Â  Â  # Verifica se o texto tem pelo menos 50 caracteres
Â  Â  if len(noticia.strip()) < 50:
Â  Â  Â  Â  raise HTTPException(
Â  Â  Â  Â  Â  Â  status_code=400,
Â  Â  Â  Â  Â  Â  detail="Texto muito curto! Por favor, envie uma notÃ­cia com pelo menos 50 caracteres."
Â  Â  Â  Â  )

Â  Â  if G is None or nlp is None:
Â  Â  Â  Â  raise HTTPException(
Â  Â  Â  Â  Â  Â  status_code=500,
Â  Â  Â  Â  Â  Â  detail="Recursos nÃ£o foram carregados corretamente"
Â  Â  Â  Â  )

Â  Â  try:
Â  Â  Â  Â  _, classificacao = verificar_noticia_completa(noticia)

Â  Â  Â  Â  if classificacao == "falsa":
Â  Â  Â  Â  Â  Â  return "Essa notÃ­cia pode ser falsa!ğŸ˜• Recomendamos procurar informaÃ§Ãµes em fontes confiÃ¡veis."
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  return "Essa notÃ­cia parece ser verdadeira!ğŸ˜„ Recomendamos buscar fontes confiÃ¡veis antes de divulgÃ¡-la."

Â  Â  except Exception as e:
Â  Â  Â  Â  raise HTTPException(
Â  Â  Â  Â  Â  Â  status_code=500,
Â  Â  Â  Â  Â  Â  detail=f"Erro durante o processamento: {str(e)}"
Â  Â  Â  Â  )

# Ponto de entrada para execuÃ§Ã£o direta
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="127.0.0.1", port=8000)
